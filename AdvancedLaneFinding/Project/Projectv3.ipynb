{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(imgs_path, nx, ny):\n",
    "    images = glob.glob(imgs_path + \"/cal*.jpg\")\n",
    "    # images = os.listdir(imgs_path)\n",
    "    objpoints = [] \n",
    "    imgpoints = []\n",
    "\n",
    "        \n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        objp = np.zeros((nx*ny, 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        if ret is True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    return objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_undist_img(img, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "objpoints, imgpoints = calibrate_camera(\"camera_cal/\", 9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_img = cv2.imread(\"camera_cal/calibration1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "undist = get_undist_img(chess_img, objpoints, imgpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imwrite(\"../notes/images/chess_img.jpg\", chess_img)\n",
    "# cv2.imwrite(\"../notes/images/undistorted_chess.jpg\", undistorted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, sobel_kernel=3, orient='x',  thresh=(100,255)):\n",
    "    if orient=='x':\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    if orient=='y':\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    sobelabs = np.abs(sobel)\n",
    "    scaledsobel = np.uint8(255*sobelabs/np.max(sobelabs))\n",
    "    sbinary = np.zeros_like(scaledsobel)\n",
    "    sbinary[(scaledsobel >= thresh[0]) & (scaledsobel <= thresh[1])] = 255\n",
    "    return sbinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "    magnitude = np.sqrt((sobelx)**2 + (sobely)**2)\n",
    "    scaledsobel = np.uint8(255*magnitude/np.max(magnitude))\n",
    "    sbinary = np.zeros_like(scaledsobel)\n",
    "    sbinary[(scaledsobel >= mag_thresh[0]) & (scaledsobel <= mag_thresh[1])] = 255\n",
    "    return sbinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0.7, 1.3)):\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.abs(sobelx)\n",
    "    abs_sobely = np.abs(sobely)\n",
    "    direction = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    binary_output = np.zeros_like(direction)\n",
    "    binary_output[(direction >= thresh[0]) & (direction <= thresh[1])] = 255\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"test_images_new/502.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "undist = get_undist_img(img, objpoints, imgpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"../notes/images/undist.jpg\", undist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(undist_img):\n",
    "    offset = 50\n",
    "    src = np.float32([[558, 462],\n",
    "                  [740, 462],\n",
    "                  [1230, undist_img.shape[0]],\n",
    "                  [undist_img.shape[1] / 7, undist_img.shape[0]]\n",
    "                 ])\n",
    "\n",
    "    dst = np.float32([[undist_img.shape[1] / 9 , offset],\n",
    "                 [undist_img.shape[1] + offset, offset],\n",
    "                 [undist_img.shape[1] - offset, undist_img.shape[0]],\n",
    "                 [undist_img.shape[1] / 6, undist_img.shape[0]]])\n",
    "\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    warped = cv2.warpPerspective(undist_img, M, undist_img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(undist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped, M, Minv = perspective_transform(undist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"../notes/images/warped_straightlines.jpg\", warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_pipeline(img, l_thresh = (120, 255), s_thresh=(120, 255), sx_thresh=(20, 255)):\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    s_channel = hls[...,2]\n",
    "    l_channel = hls[...,1]\n",
    "    h_channel = hls[...,0]\n",
    "    \n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Sobel x with l_channel for shadow in the road\n",
    "    sobelx_l = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0)\n",
    "    abs_sobelx_l = np.absolute(sobelx_l)\n",
    "    scaled_sobel_l = np.uint8(255*abs_sobelx_l/np.max(abs_sobelx_l))\n",
    "    \n",
    "    # sobelx in s channel\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 255\n",
    "\n",
    "    # sobelx in l channel\n",
    "    sxbinary_l = np.zeros_like(scaled_sobel_l)\n",
    "    sxbinary_l[(scaled_sobel_l >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 255\n",
    "    \n",
    "    \n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 255\n",
    "\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 255\n",
    "    \n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) \n",
    "\n",
    "\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[ ((sxbinary == 255) | (sxbinary_l == 255)) | ((s_binary == 255) & (l_binary == 255)) ] = 255\n",
    "    \n",
    "    gradient_combined = np.zeros_like(sxbinary)\n",
    "    gradient_combined[((sxbinary==255) | (sxbinary_l) == 255)] =255\n",
    "    \n",
    "    \n",
    "    color_combined = np.zeros_like(sxbinary)\n",
    "    color_combined[((s_binary==255) & (l_binary==255))] = 255\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_binary  = color_pipeline(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(combined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"../notes/images/combined_binary.jpg\", combined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint \n",
    "\n",
    "    nwindows = 9\n",
    "    margin = 50\n",
    "    minpix = 50\n",
    "\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "\n",
    "    nonzero = binary_warped.nonzero()\n",
    "\n",
    "    nonzeroy = np.array(nonzero[0]) \n",
    "    nonzerox = np.array(nonzero[1]) \n",
    "\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "   \n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0, 255, 0), 3)\n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0, 255, 0), 3)\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftx, lefty, rightx, righty, out_img = find_lane_pixels(combined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    return left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_search_around_poly(binary_warped, left_fit, right_fit):\n",
    "\n",
    "    margin = 70\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) &\n",
    "                      (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) &\n",
    "                      (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin,\n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin,\n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    left_pts = np.vstack((left_fitx, ploty)).astype(np.int32).T\n",
    "    right_pts = np.vstack((right_fitx, ploty)).astype(np.int32).T\n",
    "    cv2.polylines(result, [left_pts], False, (0, 255, 255), 10)\n",
    "    cv2.polylines(result, [right_pts], False, (0, 255, 255), 10)\n",
    "\n",
    "    return result, left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, left_fitx, right_fitx, ploty = old_search_around_poly(combined_binary,\n",
    "                                                             left_fit, right_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_around_poly(undist, binary_warped, Minv, left_fit, right_fit):\n",
    "\n",
    "\n",
    "    margin = 70\n",
    "\n",
    "\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) &\n",
    "                      (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) &\n",
    "                      (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "\n",
    "    \n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "\n",
    "\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    lanes_img = np.zeros_like(out_img)\n",
    "\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    cv2.fillPoly(lanes_img, np.int_([pts]), (0, 55, 0))\n",
    "    \n",
    "    \n",
    "    ## Yellow fitted lines. To see if this is usefull to \n",
    "    # get the position of the car\n",
    "    left_pts = np.vstack((left_fitx, ploty)).astype(np.int32).T\n",
    "    right_pts = np.vstack((right_fitx, ploty)).astype(np.int32).T\n",
    "#     cv2.polylines(result, [left_pts], False, (255, 255, 0), 10)\n",
    "#     cv2.polylines(result, [right_pts], False, (255, 255, 0), 10)\n",
    "    \n",
    "    \n",
    "    # Color in left and right line pixels\n",
    "    lanes_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [0, 0, 255]\n",
    "    lanes_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [255, 0, 0]\n",
    "    \n",
    "    newwarp = cv2.warpPerspective(lanes_img, Minv, (lanes_img.shape[1], lanes_img.shape[0]))\n",
    "    \n",
    "    \n",
    "    output = cv2.addWeighted(undist, 0.8, newwarp, 1, 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return output, left_pts, right_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, left_pts, right_pts = search_around_poly(undist, combined_binary, Minv, left_fit, right_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[573,   0],\n",
       "       [572,   1],\n",
       "       [572,   2],\n",
       "       ..., \n",
       "       [231, 717],\n",
       "       [231, 718],\n",
       "       [231, 719]], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_pixels():\n",
    "    leftx, lefty, rightx, righty, _ = find_lane_pixels(combined_binary)\n",
    "\n",
    "\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, combined_binary.shape[0]-1, combined_binary.shape[0] )\n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_curverad, right_curverad = measure_curvature_pixels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(img):\n",
    "    ym_per_pix = 30/720\n",
    "    xm_per_pix = 3.7/900\n",
    "    \n",
    "    leftx, lefty, rightx, righty, _ = find_lane_pixels(img)\n",
    "    \n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    \n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_curverad, right_curverad = measure_curvature_real(combined_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def proc_pipeline_tmp(img, objpoints, imgpoints):\n",
    "\n",
    "#     undist = get_undist_img(img, objpoints, imgpoints)\n",
    "#     warped_img, M, Minv = perspective_transform(undist)\n",
    "#     combined_binary = color_pipeline(warped_img)\n",
    "#     leftx, lefty, rightx, righty, out_img = find_lane_pixels(combined_binary)\n",
    "    \n",
    "#     return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_location(warped, left_pts, right_pts):\n",
    "    xm_per_pix = 3.7/900\n",
    "    dist_right = right_pts[-1][0] \n",
    "    dist_left = left_pts[-1][0]\n",
    "    main_dist = (dist_right+dist_left)/2 - warped.shape[1]/2\n",
    "    main_dist = main_dist*xm_per_pix\n",
    "    \n",
    "    \n",
    "\n",
    "    return main_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a+b)/2 - W/2, where W is the width of the birds-eye view image. Of course, this has to be converted to meters with the help of xm_per_pix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_pipeline_video(img, objpoints, imgpoints):\n",
    "\n",
    "    undist = get_undist_img(img, objpoints, imgpoints)\n",
    "    warped_img, M, Minv = perspective_transform(undist)\n",
    "    combined_binary = color_pipeline(warped_img)\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(combined_binary)\n",
    "\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "\n",
    "\n",
    "    left_curverad, right_curverad = measure_curvature_real(combined_binary)\n",
    "    \n",
    "    output, left_pts, right_pts = search_around_poly(undist, combined_binary, Minv, left_fit, right_fit)\n",
    "    \n",
    "    main_dist = compute_location(warped_img, left_pts, right_pts)\n",
    "    \n",
    "    \n",
    "    cv2.putText(output, \"Radius: \" + str(int(left_curverad)) + \"(m)\", \n",
    "            (output.shape[0] // 2, output.shape[1] // 8), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255))\n",
    "        \n",
    "    cv2.putText(output, \"Vehicle is : \" + str(round(main_dist, 2)) + \" (m) to the left\",\n",
    "            (output.shape[0] // 2, output.shape[1] // 6),\n",
    "        cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://answers.opencv.org/question/200077/combine-several-videos-in-the-same-window-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_frame(frame, factor=2):\n",
    "    resized = cv2.resize(frame, (frame.shape[1] // factor, frame.shape[0] // factor),\n",
    "                         fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video(\"test_videos/project_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Several images\n",
    "\n",
    "# cap1 = cv2.VideoCapture(\"test_videos/project_video.mp4\")\n",
    "\n",
    "\n",
    "# while (cap1.isOpened()):\n",
    "#     ret, frame = cap1.read()\n",
    "#     if ret:\n",
    "#         combined = proc_pipeline_tmp(frame, objpoints, imgpoints)\n",
    "#         full = proc_pipeline_video(frame, objpoints, imgpoints)\n",
    "#         pro = proc_pipeline_tmp(frame, objpoints, imgpoints) \n",
    "#         pro2 = proc_pipeline_tmp(frame, objpoints, imgpoints)\n",
    "\n",
    "#         combined_res = resize_frame(combined)\n",
    "#         full_res = resize_frame(full)\n",
    "#         pro_res = resize_frame(pro)\n",
    "#         pro2_res = resize_frame(pro2)\n",
    "\n",
    "\n",
    "#         both = np.concatenate((combined_res, full_res), axis=1)\n",
    "#         both2 = np.concatenate((pro_res, pro2_res), axis=1)\n",
    "#         all_4 = np.concatenate((both, both2), axis=0)\n",
    "#         cv2.imshow(\"frame\", all_4)\n",
    "        \n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     else:\n",
    "#         break\n",
    "# # Release everything if job is finished\n",
    "# cap1.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://opencv-users.1802565.n2.nabble.com/Combining-Multiple-videos-td2188079.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_img_from_video(video_path):\n",
    "    count = 0\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    while (video_capture.isOpened()):\n",
    "        ret, frame = video_capture.read()\n",
    "        if ret:\n",
    "            cv2.putText(frame, \"{}\".format(count), (frame.shape[0] // 2, frame.shape[1] // 5), \n",
    "            cv2.FONT_HERSHEY_COMPLEX_SMALL, 4, (255, 255, 255))\n",
    "            \n",
    "            undist = get_undist_img(frame, objpoints, imgpoints)\n",
    "            warped_img, M, Minv = perspective_transform(undist)\n",
    "            combined_binary = color_pipeline(warped_img)\n",
    "            \n",
    "            result, _, _, _ = old_search_around_poly(combined_binary,\n",
    "                                                             left_fit, right_fit)\n",
    "            \n",
    "            output, _, _ = search_around_poly(undist, combined_binary, Minv, left_fit, right_fit)\n",
    "            \n",
    "            \n",
    "            cv2.imshow('frame',frame)\n",
    "            \n",
    "            cv2.imwrite('test_images_new/' + str(count) + \".jpg\", frame)\n",
    "            cv2.imwrite(\"test_images_new/\" + str(count) + \"warped.jpg\", warped_img)\n",
    "            cv2.imwrite(\"test_images_new/\" + str(count) + \"combined_binary.jpg\", combined_binary)\n",
    "            cv2.imwrite(\"test_images_new/\" + str(count) + \"output.jpg\", output)\n",
    "            cv2.imwrite(\"test_images_new/\" + str(count) + \"fitted.jpg\", result)\n",
    "            \n",
    "            \n",
    "            video_capture.set(cv2.CAP_PROP_POS_MSEC, (count*50))\n",
    "            \n",
    "            count += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    # Release everything if job is finished\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_img_from_video(\"test_videos/project_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   4%|▍         | 56/1260 [37:05<14:14,  1.41it/s, now=None]\n",
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/project_video_output.mp4.\n",
      "Moviepy - Writing video test_videos_output/project_video_output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "t:   0%|          | 2/1260 [00:00<07:38,  2.75it/s, now=None]\u001b[A\n",
      "t:   0%|          | 3/1260 [00:01<09:56,  2.11it/s, now=None]\u001b[A\n",
      "t:   0%|          | 4/1260 [00:02<11:31,  1.82it/s, now=None]\u001b[A\n",
      "t:   0%|          | 5/1260 [00:02<12:34,  1.66it/s, now=None]\u001b[A\n",
      "t:   0%|          | 6/1260 [00:03<13:19,  1.57it/s, now=None]\u001b[A\n",
      "t:   1%|          | 7/1260 [00:04<13:50,  1.51it/s, now=None]\u001b[A\n",
      "t:   1%|          | 8/1260 [00:05<14:08,  1.47it/s, now=None]\u001b[A\n",
      "t:   1%|          | 9/1260 [00:05<14:22,  1.45it/s, now=None]\u001b[A\n",
      "t:   1%|          | 10/1260 [00:06<14:30,  1.44it/s, now=None]\u001b[A\n",
      "t:   1%|          | 11/1260 [00:07<14:47,  1.41it/s, now=None]\u001b[A\n",
      "t:   1%|          | 12/1260 [00:07<14:51,  1.40it/s, now=None]\u001b[A\n",
      "t:   1%|          | 13/1260 [00:08<14:55,  1.39it/s, now=None]\u001b[A\n",
      "t:   1%|          | 14/1260 [00:09<14:53,  1.39it/s, now=None]\u001b[A\n",
      "t:   1%|          | 15/1260 [00:10<14:49,  1.40it/s, now=None]\u001b[A\n",
      "t:   1%|▏         | 16/1260 [00:10<14:49,  1.40it/s, now=None]\u001b[A\n",
      "t:   1%|▏         | 17/1260 [00:11<14:45,  1.40it/s, now=None]\u001b[A\n",
      "t:   1%|▏         | 18/1260 [00:12<14:51,  1.39it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 19/1260 [00:12<14:51,  1.39it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 20/1260 [00:13<14:50,  1.39it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 21/1260 [00:14<14:47,  1.40it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 22/1260 [00:15<14:47,  1.40it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 23/1260 [00:15<14:51,  1.39it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 24/1260 [00:16<14:47,  1.39it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 25/1260 [00:17<14:57,  1.38it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 26/1260 [00:18<14:54,  1.38it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 27/1260 [00:18<14:52,  1.38it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 28/1260 [00:19<14:55,  1.38it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 29/1260 [00:20<14:53,  1.38it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 30/1260 [00:20<14:55,  1.37it/s, now=None]\u001b[A\n",
      "t:   2%|▏         | 31/1260 [00:21<14:50,  1.38it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 32/1260 [00:22<14:50,  1.38it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 33/1260 [00:23<14:53,  1.37it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 34/1260 [00:23<14:51,  1.38it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 35/1260 [00:24<14:46,  1.38it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 36/1260 [00:25<14:41,  1.39it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 37/1260 [00:25<14:39,  1.39it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 38/1260 [00:26<14:36,  1.39it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 39/1260 [00:27<14:36,  1.39it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 40/1260 [00:28<14:34,  1.39it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 41/1260 [00:28<14:32,  1.40it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 42/1260 [00:29<14:33,  1.39it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 43/1260 [00:30<14:32,  1.39it/s, now=None]\u001b[A\n",
      "t:   3%|▎         | 44/1260 [00:31<14:33,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▎         | 45/1260 [00:31<14:31,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▎         | 46/1260 [00:32<14:31,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▎         | 47/1260 [00:33<14:29,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 48/1260 [00:33<14:29,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 49/1260 [00:34<14:27,  1.40it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 50/1260 [00:35<14:28,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 51/1260 [00:36<14:24,  1.40it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 52/1260 [00:36<14:28,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 53/1260 [00:37<14:27,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 54/1260 [00:38<14:26,  1.39it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 55/1260 [00:38<14:22,  1.40it/s, now=None]\u001b[A\n",
      "t:   4%|▍         | 56/1260 [00:39<14:29,  1.38it/s, now=None]\u001b[A\n",
      "t:   5%|▍         | 57/1260 [00:40<14:34,  1.38it/s, now=None]\u001b[A\n",
      "t:   5%|▍         | 58/1260 [00:41<14:28,  1.38it/s, now=None]\u001b[A\n",
      "t:   5%|▍         | 59/1260 [00:41<14:29,  1.38it/s, now=None]\u001b[A\n",
      "t:   5%|▍         | 60/1260 [00:42<14:38,  1.37it/s, now=None]\u001b[A\n",
      "t:   5%|▍         | 61/1260 [00:43<14:33,  1.37it/s, now=None]\u001b[A\n",
      "t:   5%|▍         | 62/1260 [00:44<14:32,  1.37it/s, now=None]\u001b[A\n",
      "t:   5%|▌         | 63/1260 [00:44<14:39,  1.36it/s, now=None]\u001b[A\n",
      "t:   5%|▌         | 64/1260 [00:45<14:39,  1.36it/s, now=None]\u001b[A\n",
      "t:   5%|▌         | 65/1260 [00:46<14:39,  1.36it/s, now=None]\u001b[A\n",
      "t:   5%|▌         | 66/1260 [00:46<14:36,  1.36it/s, now=None]\u001b[A\n",
      "t:   5%|▌         | 67/1260 [00:47<14:31,  1.37it/s, now=None]\u001b[A\n",
      "t:   5%|▌         | 68/1260 [00:48<14:34,  1.36it/s, now=None]\u001b[A\n",
      "t:   5%|▌         | 69/1260 [00:49<14:27,  1.37it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 70/1260 [00:49<14:30,  1.37it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 71/1260 [00:50<14:23,  1.38it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 72/1260 [00:51<14:17,  1.39it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 73/1260 [00:52<14:18,  1.38it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 74/1260 [00:52<14:21,  1.38it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 75/1260 [00:53<14:22,  1.37it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 76/1260 [00:54<14:15,  1.38it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 77/1260 [00:54<14:19,  1.38it/s, now=None]\u001b[A\n",
      "t:   6%|▌         | 78/1260 [00:55<14:28,  1.36it/s, now=None]\u001b[A\n",
      "t:   6%|▋         | 79/1260 [00:56<14:22,  1.37it/s, now=None]\u001b[A\n",
      "t:   6%|▋         | 80/1260 [00:57<14:21,  1.37it/s, now=None]\u001b[A\n",
      "t:   6%|▋         | 81/1260 [00:57<14:16,  1.38it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 82/1260 [00:58<14:18,  1.37it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 83/1260 [00:59<14:20,  1.37it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 84/1260 [01:00<14:17,  1.37it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 85/1260 [01:00<14:14,  1.37it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 86/1260 [01:01<14:15,  1.37it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 87/1260 [01:02<14:20,  1.36it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 88/1260 [01:03<14:20,  1.36it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 89/1260 [01:03<14:19,  1.36it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 90/1260 [01:04<14:12,  1.37it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 91/1260 [01:05<14:12,  1.37it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 92/1260 [01:05<14:12,  1.37it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 93/1260 [01:06<14:25,  1.35it/s, now=None]\u001b[A\n",
      "t:   7%|▋         | 94/1260 [01:07<14:26,  1.35it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 95/1260 [01:08<14:22,  1.35it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 96/1260 [01:08<14:21,  1.35it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 97/1260 [01:09<14:11,  1.37it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 98/1260 [01:10<14:14,  1.36it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 99/1260 [01:11<14:15,  1.36it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 100/1260 [01:11<14:08,  1.37it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 101/1260 [01:12<14:07,  1.37it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 102/1260 [01:13<14:13,  1.36it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 103/1260 [01:14<14:08,  1.36it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 104/1260 [01:14<14:12,  1.36it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 105/1260 [01:15<14:04,  1.37it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 106/1260 [01:16<14:00,  1.37it/s, now=None]\u001b[A\n",
      "t:   8%|▊         | 107/1260 [01:16<13:55,  1.38it/s, now=None]\u001b[A\n",
      "t:   9%|▊         | 108/1260 [01:17<13:53,  1.38it/s, now=None]\u001b[A\n",
      "t:   9%|▊         | 109/1260 [01:18<13:58,  1.37it/s, now=None]\u001b[A\n",
      "t:   9%|▊         | 110/1260 [01:19<13:52,  1.38it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 111/1260 [01:19<13:45,  1.39it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 112/1260 [01:20<13:46,  1.39it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 113/1260 [01:21<13:45,  1.39it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 114/1260 [01:21<13:43,  1.39it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 115/1260 [01:22<13:43,  1.39it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 116/1260 [01:23<13:43,  1.39it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 117/1260 [01:24<13:41,  1.39it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 118/1260 [01:24<13:35,  1.40it/s, now=None]\u001b[A\n",
      "t:   9%|▉         | 119/1260 [01:25<13:38,  1.39it/s, now=None]\u001b[A\n",
      "t:  10%|▉         | 120/1260 [01:26<13:40,  1.39it/s, now=None]\u001b[A\n",
      "t:  10%|▉         | 121/1260 [01:27<13:44,  1.38it/s, now=None]\u001b[A\n",
      "t:  10%|▉         | 122/1260 [01:27<13:40,  1.39it/s, now=None]\u001b[A\n",
      "t:  10%|▉         | 123/1260 [01:28<13:40,  1.38it/s, now=None]\u001b[A\n",
      "t:  10%|▉         | 124/1260 [01:29<13:43,  1.38it/s, now=None]\u001b[A\n",
      "t:  10%|▉         | 125/1260 [01:29<13:41,  1.38it/s, now=None]\u001b[A\n",
      "t:  10%|█         | 126/1260 [01:30<13:36,  1.39it/s, now=None]\u001b[A\n",
      "t:  10%|█         | 127/1260 [01:31<13:37,  1.39it/s, now=None]\u001b[A\n",
      "t:  10%|█         | 128/1260 [01:32<13:39,  1.38it/s, now=None]\u001b[A\n",
      "t:  10%|█         | 129/1260 [01:32<13:43,  1.37it/s, now=None]\u001b[A\n",
      "t:  10%|█         | 130/1260 [01:33<13:44,  1.37it/s, now=None]\u001b[A\n",
      "t:  10%|█         | 131/1260 [01:34<13:49,  1.36it/s, now=None]\u001b[A\n",
      "t:  10%|█         | 132/1260 [01:34<13:41,  1.37it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 133/1260 [01:35<13:38,  1.38it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 134/1260 [01:36<13:33,  1.38it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 135/1260 [01:37<13:33,  1.38it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 136/1260 [01:37<13:30,  1.39it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 137/1260 [01:38<13:30,  1.39it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 138/1260 [01:39<13:31,  1.38it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 139/1260 [01:40<13:27,  1.39it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 140/1260 [01:40<13:32,  1.38it/s, now=None]\u001b[A\n",
      "t:  11%|█         | 141/1260 [01:41<13:29,  1.38it/s, now=None]\u001b[A\n",
      "t:  11%|█▏        | 142/1260 [01:42<13:31,  1.38it/s, now=None]\u001b[A\n",
      "t:  11%|█▏        | 143/1260 [01:42<13:27,  1.38it/s, now=None]\u001b[A\n",
      "t:  11%|█▏        | 144/1260 [01:43<13:24,  1.39it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 145/1260 [01:44<13:25,  1.38it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 146/1260 [01:45<13:24,  1.38it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 147/1260 [01:45<13:25,  1.38it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 148/1260 [01:46<13:22,  1.39it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 149/1260 [01:47<13:19,  1.39it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 150/1260 [01:47<13:21,  1.38it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 151/1260 [01:48<13:18,  1.39it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 152/1260 [01:49<13:18,  1.39it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 153/1260 [01:50<13:17,  1.39it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 154/1260 [01:50<13:13,  1.39it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 155/1260 [01:51<13:12,  1.40it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 156/1260 [01:52<13:09,  1.40it/s, now=None]\u001b[A\n",
      "t:  12%|█▏        | 157/1260 [01:53<13:10,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 158/1260 [01:53<13:10,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 159/1260 [01:54<13:13,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 160/1260 [01:55<13:10,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 161/1260 [01:55<13:10,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 162/1260 [01:56<13:09,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 163/1260 [01:57<13:07,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 164/1260 [01:58<13:12,  1.38it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 165/1260 [01:58<13:14,  1.38it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 166/1260 [01:59<13:11,  1.38it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 167/1260 [02:00<13:08,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 168/1260 [02:00<13:05,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 169/1260 [02:01<13:05,  1.39it/s, now=None]\u001b[A\n",
      "t:  13%|█▎        | 170/1260 [02:02<12:59,  1.40it/s, now=None]\u001b[A\n",
      "t:  14%|█▎        | 171/1260 [02:03<13:02,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▎        | 172/1260 [02:03<13:03,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▎        | 173/1260 [02:04<13:03,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 174/1260 [02:05<13:04,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 175/1260 [02:05<13:05,  1.38it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 176/1260 [02:06<13:00,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 177/1260 [02:07<12:58,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 178/1260 [02:08<12:59,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 179/1260 [02:08<13:01,  1.38it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 180/1260 [02:09<12:55,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 181/1260 [02:10<12:56,  1.39it/s, now=None]\u001b[A\n",
      "t:  14%|█▍        | 182/1260 [02:11<12:55,  1.39it/s, now=None]\u001b[A\n",
      "t:  15%|█▍        | 183/1260 [02:11<12:52,  1.39it/s, now=None]\u001b[A\n",
      "t:  15%|█▍        | 184/1260 [02:12<12:51,  1.39it/s, now=None]\u001b[A\n",
      "t:  15%|█▍        | 185/1260 [02:13<12:56,  1.38it/s, now=None]\u001b[A\n",
      "t:  15%|█▍        | 186/1260 [02:13<13:07,  1.36it/s, now=None]\u001b[A\n",
      "t:  15%|█▍        | 187/1260 [02:14<13:03,  1.37it/s, now=None]\u001b[A\n",
      "t:  15%|█▍        | 188/1260 [02:15<13:12,  1.35it/s, now=None]\u001b[A\n",
      "t:  15%|█▌        | 189/1260 [02:16<13:13,  1.35it/s, now=None]\u001b[A\n",
      "t:  15%|█▌        | 190/1260 [02:16<13:12,  1.35it/s, now=None]\u001b[A\n",
      "t:  15%|█▌        | 191/1260 [02:17<13:01,  1.37it/s, now=None]\u001b[A\n",
      "t:  15%|█▌        | 192/1260 [02:18<13:04,  1.36it/s, now=None]\u001b[A\n",
      "t:  15%|█▌        | 193/1260 [02:19<12:58,  1.37it/s, now=None]\u001b[A\n",
      "t:  15%|█▌        | 194/1260 [02:19<13:00,  1.37it/s, now=None]\u001b[A\n",
      "t:  15%|█▌        | 195/1260 [02:20<12:52,  1.38it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 196/1260 [02:21<12:49,  1.38it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 197/1260 [02:21<12:48,  1.38it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 198/1260 [02:22<12:47,  1.38it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 199/1260 [02:23<12:46,  1.38it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 200/1260 [02:24<12:45,  1.39it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 201/1260 [02:24<12:39,  1.39it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 202/1260 [02:25<12:42,  1.39it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 203/1260 [02:26<12:40,  1.39it/s, now=None]\u001b[A\n",
      "t:  16%|█▌        | 204/1260 [02:27<12:39,  1.39it/s, now=None]\u001b[A\n",
      "t:  16%|█▋        | 205/1260 [02:27<12:37,  1.39it/s, now=None]\u001b[A\n",
      "t:  16%|█▋        | 206/1260 [02:28<12:38,  1.39it/s, now=None]\u001b[A\n",
      "t:  16%|█▋        | 207/1260 [02:29<12:36,  1.39it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 208/1260 [02:29<12:34,  1.39it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 209/1260 [02:30<12:40,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 210/1260 [02:31<12:40,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 211/1260 [02:32<12:40,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 212/1260 [02:32<12:38,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 213/1260 [02:33<12:36,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 214/1260 [02:34<12:35,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 215/1260 [02:34<12:32,  1.39it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 216/1260 [02:35<12:34,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 217/1260 [02:36<12:34,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 218/1260 [02:37<12:37,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 219/1260 [02:37<12:34,  1.38it/s, now=None]\u001b[A\n",
      "t:  17%|█▋        | 220/1260 [02:38<12:34,  1.38it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 221/1260 [02:39<12:35,  1.38it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 222/1260 [02:40<12:33,  1.38it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 223/1260 [02:40<12:34,  1.37it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 224/1260 [02:41<12:37,  1.37it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 225/1260 [02:42<12:39,  1.36it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 226/1260 [02:42<12:37,  1.37it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 227/1260 [02:43<12:35,  1.37it/s, now=None]\u001b[A\n",
      "t:  18%|█▊        | 228/1260 [02:44<12:31,  1.37it/s, now=None]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m</home/samuel/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/decorator.py:decorator-gen-175>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/samuel/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/decorator.py:decorator-gen-174>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    135\u001b[0m              for (k,v) in k.items()}\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m</home/samuel/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/decorator.py:decorator-gen-173>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    324\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                            \u001b[0mffmpeg_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mffmpeg_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                            logger=logger)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         for t,frame in clip.iter_frames(logger=logger, with_times=True,\n\u001b[0;32m--> 216\u001b[0;31m                                         fps=fps, dtype=\"uint8\"):\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36miter_frames\u001b[0;34m(self, fps, with_times, logger, dtype)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproglog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bar_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/samuel/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/decorator.py:decorator-gen-134>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mapply_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-b27dd07a32ab>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclip1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_videos/project_video.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwhite_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mproc_pipeline_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'white_clip.write_videofile(white_output, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-d38ce25dd83e>\u001b[0m in \u001b[0;36mproc_pipeline_video\u001b[0;34m(img, objpoints, imgpoints)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mproc_pipeline_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mundist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_undist_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mwarped_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperspective_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcombined_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9608eedcc426>\u001b[0m in \u001b[0;36mget_undist_img\u001b[0;34m(img, objpoints, imgpoints)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_undist_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mundist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mundist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/project_video_output.mp4'\n",
    "\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\")\n",
    "white_clip = clip1.fl_image(lambda img: proc_pipeline_video(img, objpoints, imgpoints)) \n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
